{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of doing autoregression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXIw61Dk-M5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from statsmodels.tsa.api import VAR\n",
        "from sklearn.metrics import mean_squared_error as mse"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkJ8yu1RV6KA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1e512f4-8d8b-437d-d72a-f5060ad1e02f"
      },
      "source": [
        "### Load data. The data is part of HCP dataset, contains \"match\" block in relational task run 1\n",
        "### Dimension of the data is 1017 * 23 * 360 (#trials * MRI frames * cortex parcels)\n",
        "\n",
        "with open('AR_data.pkl', 'rb') as fh:\n",
        "    relational_HCP = pickle.load(fh)[0]\n",
        "\n",
        "np.shape(relational_HCP)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1017, 23, 360)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ira_DBk7839Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Functions to run and test autoregression model\n",
        "\n",
        "def run_ar(data, lag):\n",
        "  '''\n",
        "  Running autoregression model on the data.\n",
        "\n",
        "  Input:\n",
        "  data: # of trials * frames * parcels\n",
        "  lag: int\n",
        "\n",
        "  Return:\n",
        "  coef: # of trials * lag * parcels * parcels\n",
        "  sigma_u: # of trials * parcels * parcels\n",
        "\n",
        "  '''\n",
        "\n",
        "  coef = []\n",
        "  sigma_u = []\n",
        "\n",
        "  num = len(data)\n",
        "  for ii in range(num):\n",
        "    if ii%100 == 0:\n",
        "      print(f\"{ii} / {num}\")\n",
        "\n",
        "    # if np.shape(data[ii]) != shape:\n",
        "    #   continue\n",
        "\n",
        "    curr_model = VAR(data[ii])\n",
        "    curr_result = curr_model.fit(lag)\n",
        "\n",
        "    coef.append(curr_result.coefs)\n",
        "    sigma_u.append(curr_result.sigma_u)\n",
        "  \n",
        "  return coef, sigma_u\n",
        "\n",
        "def test_ar(data, coef, sigma_u, lag, prop):\n",
        "  '''\n",
        "  Randomly choose a set of test data for testing model coef.\n",
        "  Baseline preformance is persistance model (x_t = x_{t-1}).\n",
        "  Print the number of datapoints where model is better, and the average baseline and model mse.\n",
        "\n",
        "  Input:\n",
        "  data: # of trials * frames * parcels\n",
        "  coef: # of trials * lag * parcels * parcels, output from run_ar\n",
        "  sigma_u: # of trials * parcels * parcels, output from run_ar\n",
        "  lag: int\n",
        "  prop: proportion of data to be used as test data\n",
        "\n",
        "  Output:\n",
        "  baseline_mse: mse of baseline performance\n",
        "  all_mse: mse of model on test data\n",
        "\n",
        "  '''\n",
        "\n",
        "  num = len(data)\n",
        "  nframe = len(data[0])\n",
        "  all_mse = []\n",
        "  baseline_mse = []\n",
        "\n",
        "  # idx for test and train data, split test data\n",
        "  idx = np.random.randint(low = 0, high = int(1/prop), size = num)\n",
        "  idx_test = np.where(idx==0)[0]\n",
        "  idx_train = np.where(idx!=0)[0]\n",
        "  data_test = [data[x] for x in idx_test]\n",
        "\n",
        "  # params from training set\n",
        "  coef_train = [coef[x] for x in idx_train]\n",
        "  coef_train = np.average(coef_train, axis = 0)\n",
        "  sigma_u_train = [sigma_u[x] for x in idx_train]\n",
        "  sigma_u_train = np.average(sigma_u_train, axis = 0)\n",
        "\n",
        "  # baseline performance\n",
        "  for jj in range(len(idx_test)):\n",
        "    true = np.transpose(data_test[jj][lag:])\n",
        "    baseline_pred = np.transpose(data_test[jj][lag-1:-1])\n",
        "    baseline_mse.append(mse(true, baseline_pred))\n",
        "\n",
        "  # use coef of training set to test\n",
        "  if lag == 1:\n",
        "    for ii in range(len(idx_test)):\n",
        "\n",
        "      pred = np.dot(coef_train[0], np.transpose(data_test[ii][:-1]))\n",
        "      noise = np.random.multivariate_normal(mean = np.zeros(360), cov = sigma_u_train, size = nframe-lag)\n",
        "      pred = pred + noise.transpose()\n",
        "      all_mse.append(mse(data_test[ii][1:], pred.transpose()))\n",
        "\n",
        "  elif lag != 1:\n",
        "    for ii in range(len(idx_test)):\n",
        "      pred = []\n",
        "\n",
        "      for jj in range(nframe-lag):\n",
        "        temp = []\n",
        "\n",
        "        for kk in range(lag):\n",
        "          temp.append(np.dot(coef_train[kk], np.transpose(data_test[ii][kk+jj])))\n",
        "        \n",
        "        pred.append(np.sum(temp, axis = 0))\n",
        "      \n",
        "      noise = np.random.multivariate_normal(mean = np.zeros(360), cov = sigma_u_train, size = nframe-lag)\n",
        "      pred = pred + noise\n",
        "      all_mse.append(mse(data_test[ii][lag:], pred))\n",
        "\n",
        "  compare = np.less(all_mse, baseline_mse)\n",
        "  print(f\"Num of model mse less than baseline mse: {sum(compare)}/{len(idx_test)}\")\n",
        "\n",
        "  baseline_mse = np.average(baseline_mse)\n",
        "  all_mse = np.average(all_mse)\n",
        "\n",
        "  print(f\"Average baseline mse: {baseline_mse}\\nAverage model mse: {all_mse}\")\n",
        "\n",
        "  # return baseline_mse, all_mse"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1rPbHg4nBcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77a21d3e-e9fb-4e29-dde0-87778a767945"
      },
      "source": [
        "### Run the model for many lag value on the data\n",
        "np.random.seed(2020)\n",
        "for lag in range(1,5):\n",
        "  print(f\"Current lag num: {lag}\\nRunning AR:\")\n",
        "  curr_coef, curr_sigma_u = run_ar(relational_HCP, lag = lag)\n",
        "  print(\"Testing AR:\")\n",
        "  test_ar(data = relational_HCP, coef = curr_coef, sigma_u = curr_sigma_u, lag=lag, prop=0.2)\n",
        "  print('\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current lag num: 1\n",
            "Running AR:\n",
            "0 / 1017\n",
            "100 / 1017\n",
            "200 / 1017\n",
            "300 / 1017\n",
            "400 / 1017\n",
            "500 / 1017\n",
            "600 / 1017\n",
            "700 / 1017\n",
            "800 / 1017\n",
            "900 / 1017\n",
            "1000 / 1017\n",
            "Testing AR:\n",
            "Num of model mse less than baseline mse: 192/227\n",
            "Average baseline mse: 5088.078272915777\n",
            "Average model mse: 4151.6896841533835\n",
            "\n",
            "\n",
            "Current lag num: 2\n",
            "Running AR:\n",
            "0 / 1017\n",
            "100 / 1017\n",
            "200 / 1017\n",
            "300 / 1017\n",
            "400 / 1017\n",
            "500 / 1017\n",
            "600 / 1017\n",
            "700 / 1017\n",
            "800 / 1017\n",
            "900 / 1017\n",
            "1000 / 1017\n",
            "Testing AR:\n",
            "Num of model mse less than baseline mse: 165/221\n",
            "Average baseline mse: 5075.453348951435\n",
            "Average model mse: 4590.44222082113\n",
            "\n",
            "\n",
            "Current lag num: 3\n",
            "Running AR:\n",
            "0 / 1017\n",
            "100 / 1017\n",
            "200 / 1017\n",
            "300 / 1017\n",
            "400 / 1017\n",
            "500 / 1017\n",
            "600 / 1017\n",
            "700 / 1017\n",
            "800 / 1017\n",
            "900 / 1017\n",
            "1000 / 1017\n",
            "Testing AR:\n",
            "Num of model mse less than baseline mse: 168/208\n",
            "Average baseline mse: 5582.409717501336\n",
            "Average model mse: 4688.052827868265\n",
            "\n",
            "\n",
            "Current lag num: 4\n",
            "Running AR:\n",
            "0 / 1017\n",
            "100 / 1017\n",
            "200 / 1017\n",
            "300 / 1017\n",
            "400 / 1017\n",
            "500 / 1017\n",
            "600 / 1017\n",
            "700 / 1017\n",
            "800 / 1017\n",
            "900 / 1017\n",
            "1000 / 1017\n",
            "Testing AR:\n",
            "Num of model mse less than baseline mse: 153/208\n",
            "Average baseline mse: 5001.73995864738\n",
            "Average model mse: 4717.670792099618\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}